{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e076cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47247b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_windows = pd.read_csv(\"train_windows.csv\")\n",
    "test_windows = pd.read_csv(\"test_windows.csv\")\n",
    "dev_windows = pd.read_csv(\"dev_windows.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0207d80",
   "metadata": {},
   "source": [
    "We remove \"_\" class, as it doesn't serve a purpose for the classification (X is \"others\" class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cac1ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wi-1</th>\n",
       "      <th>Wi</th>\n",
       "      <th>Wi+1</th>\n",
       "      <th>Wi_POS_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>Le</td>\n",
       "      <td>infrastrutture</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le</td>\n",
       "      <td>infrastrutture</td>\n",
       "      <td>come</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>infrastrutture</td>\n",
       "      <td>come</td>\n",
       "      <td>fattore</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>come</td>\n",
       "      <td>fattore</td>\n",
       "      <td>di</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fattore</td>\n",
       "      <td>di</td>\n",
       "      <td>competitività</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183845</th>\n",
       "      <td>Ramondino</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;e&gt;</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183846</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>Libri</td>\n",
       "      <td>in</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183847</th>\n",
       "      <td>Libri</td>\n",
       "      <td>in</td>\n",
       "      <td>campo</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183848</th>\n",
       "      <td>in</td>\n",
       "      <td>campo</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183849</th>\n",
       "      <td>campo</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;e&gt;</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169780 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Wi-1              Wi            Wi+1 Wi_POS_tag\n",
       "0                  <s>              Le  infrastrutture        DET\n",
       "1                   Le  infrastrutture            come       NOUN\n",
       "2       infrastrutture            come         fattore        ADP\n",
       "3                 come         fattore              di       NOUN\n",
       "4              fattore              di   competitività        ADP\n",
       "...                ...             ...             ...        ...\n",
       "183845       Ramondino               .             <e>      PUNCT\n",
       "183846             <s>           Libri              in       NOUN\n",
       "183847           Libri              in           campo        ADP\n",
       "183848              in           campo               .       NOUN\n",
       "183849           campo               .             <e>      PUNCT\n",
       "\n",
       "[169780 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_windows = train_windows[train_windows['Wi_POS_tag'] != \"_\"]\n",
    "train_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e988852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wi-1</th>\n",
       "      <th>Wi</th>\n",
       "      <th>Wi+1</th>\n",
       "      <th>Wi_POS_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>Non</td>\n",
       "      <td>sono</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non</td>\n",
       "      <td>sono</td>\n",
       "      <td>consentite</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sono</td>\n",
       "      <td>consentite</td>\n",
       "      <td>assegnazioni</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>consentite</td>\n",
       "      <td>assegnazioni</td>\n",
       "      <td>provvisorie</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>assegnazioni</td>\n",
       "      <td>provvisorie</td>\n",
       "      <td>nell'ambito</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21496</th>\n",
       "      <td>dalla</td>\n",
       "      <td>storia</td>\n",
       "      <td>che</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21497</th>\n",
       "      <td>storia</td>\n",
       "      <td>che</td>\n",
       "      <td>son</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21498</th>\n",
       "      <td>che</td>\n",
       "      <td>son</td>\n",
       "      <td>per</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21499</th>\n",
       "      <td>son</td>\n",
       "      <td>per</td>\n",
       "      <td>narrarvi</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21501</th>\n",
       "      <td>narrarvi</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;e&gt;</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20068 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Wi-1            Wi          Wi+1 Wi_POS_tag\n",
       "0               <s>           Non          sono        ADV\n",
       "1               Non          sono    consentite        AUX\n",
       "2              sono    consentite  assegnazioni       VERB\n",
       "3        consentite  assegnazioni   provvisorie       NOUN\n",
       "4      assegnazioni   provvisorie   nell'ambito        ADJ\n",
       "...             ...           ...           ...        ...\n",
       "21496         dalla        storia           che       NOUN\n",
       "21497        storia           che           son       PRON\n",
       "21498           che           son           per       VERB\n",
       "21499           son           per      narrarvi        ADP\n",
       "21501      narrarvi             .           <e>      PUNCT\n",
       "\n",
       "[20068 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_windows = test_windows[test_windows['Wi_POS_tag'] != \"_\"]\n",
    "test_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd6032e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wi-1</th>\n",
       "      <th>Wi</th>\n",
       "      <th>Wi+1</th>\n",
       "      <th>Wi_POS_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>Ha</td>\n",
       "      <td>l'acqua</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l'acqua</td>\n",
       "      <td>calda</td>\n",
       "      <td>,</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calda</td>\n",
       "      <td>,</td>\n",
       "      <td>più</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>più</td>\n",
       "      <td>o</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>più</td>\n",
       "      <td>o</td>\n",
       "      <td>meno</td>\n",
       "      <td>CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23665</th>\n",
       "      <td>che</td>\n",
       "      <td>possono</td>\n",
       "      <td>richiedere</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23666</th>\n",
       "      <td>possono</td>\n",
       "      <td>richiedere</td>\n",
       "      <td>per</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23667</th>\n",
       "      <td>richiedere</td>\n",
       "      <td>per</td>\n",
       "      <td>trasferimento</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23668</th>\n",
       "      <td>per</td>\n",
       "      <td>trasferimento</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23669</th>\n",
       "      <td>trasferimento</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;e&gt;</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21432 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Wi-1             Wi           Wi+1 Wi_POS_tag\n",
       "0                <s>             Ha        l'acqua       VERB\n",
       "1            l'acqua          calda              ,        ADJ\n",
       "2              calda              ,            più      PUNCT\n",
       "3                  ,            più              o        ADV\n",
       "4                più              o           meno      CCONJ\n",
       "...              ...            ...            ...        ...\n",
       "23665            che        possono     richiedere        AUX\n",
       "23666        possono     richiedere            per       VERB\n",
       "23667     richiedere            per  trasferimento        ADP\n",
       "23668            per  trasferimento              .       NOUN\n",
       "23669  trasferimento              .            <e>      PUNCT\n",
       "\n",
       "[21432 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_windows = dev_windows[dev_windows['Wi_POS_tag'] != \"_\"]\n",
    "dev_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7107f6f8",
   "metadata": {},
   "source": [
    "## Window Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1663f92f",
   "metadata": {},
   "source": [
    "We used a pretrained Italian word embedding model from fasttext, with 300 dimension vectors, to transform our window words to vectors. The window embedding was the concat of the 3 vectors of the window, a 900 dimension vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe36f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "# fasttext.util.download_model('it', if_exists='ignore')  # Italian\n",
    "ft = fasttext.load_model('cc.it.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fcad028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vector(word):\n",
    "    try:\n",
    "        return ft.get_word_vector(str(word))\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "# Apply the function to the 'text_column' to get vectors for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19198ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_windows['Ei-1'] = train_windows['Wi-1'].apply(get_word_vector)\n",
    "train_windows['Ei'] = train_windows['Wi'].apply(get_word_vector)\n",
    "train_windows['Ei+1'] = train_windows['Wi+1'].apply(get_word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e25ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wi-1</th>\n",
       "      <th>Wi</th>\n",
       "      <th>Wi+1</th>\n",
       "      <th>Wi_POS_tag</th>\n",
       "      <th>Ei-1</th>\n",
       "      <th>Ei</th>\n",
       "      <th>Ei+1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>Le</td>\n",
       "      <td>infrastrutture</td>\n",
       "      <td>DET</td>\n",
       "      <td>[-0.020176327, 0.009958053, 0.021717465, 0.001...</td>\n",
       "      <td>[-0.106553055, 0.06714334, -0.0022430907, -0.0...</td>\n",
       "      <td>[-0.029298682, 0.021048546, 0.03234201, -0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le</td>\n",
       "      <td>infrastrutture</td>\n",
       "      <td>come</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[-0.106553055, 0.06714334, -0.0022430907, -0.0...</td>\n",
       "      <td>[-0.029298682, 0.021048546, 0.03234201, -0.003...</td>\n",
       "      <td>[0.0020916015, -0.009661912, 0.050255135, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>infrastrutture</td>\n",
       "      <td>come</td>\n",
       "      <td>fattore</td>\n",
       "      <td>ADP</td>\n",
       "      <td>[-0.029298682, 0.021048546, 0.03234201, -0.003...</td>\n",
       "      <td>[0.0020916015, -0.009661912, 0.050255135, -0.0...</td>\n",
       "      <td>[0.020856846, -0.038480032, -0.007763977, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>come</td>\n",
       "      <td>fattore</td>\n",
       "      <td>di</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[0.0020916015, -0.009661912, 0.050255135, -0.0...</td>\n",
       "      <td>[0.020856846, -0.038480032, -0.007763977, 0.01...</td>\n",
       "      <td>[-0.02089869, -0.04530562, 0.2433449, 0.021318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fattore</td>\n",
       "      <td>di</td>\n",
       "      <td>competitività</td>\n",
       "      <td>ADP</td>\n",
       "      <td>[0.020856846, -0.038480032, -0.007763977, 0.01...</td>\n",
       "      <td>[-0.02089869, -0.04530562, 0.2433449, 0.021318...</td>\n",
       "      <td>[0.027081296, 0.008981515, 0.018652983, 0.0216...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Wi-1              Wi            Wi+1 Wi_POS_tag  \\\n",
       "0             <s>              Le  infrastrutture        DET   \n",
       "1              Le  infrastrutture            come       NOUN   \n",
       "2  infrastrutture            come         fattore        ADP   \n",
       "3            come         fattore              di       NOUN   \n",
       "4         fattore              di   competitività        ADP   \n",
       "\n",
       "                                                Ei-1  \\\n",
       "0  [-0.020176327, 0.009958053, 0.021717465, 0.001...   \n",
       "1  [-0.106553055, 0.06714334, -0.0022430907, -0.0...   \n",
       "2  [-0.029298682, 0.021048546, 0.03234201, -0.003...   \n",
       "3  [0.0020916015, -0.009661912, 0.050255135, -0.0...   \n",
       "4  [0.020856846, -0.038480032, -0.007763977, 0.01...   \n",
       "\n",
       "                                                  Ei  \\\n",
       "0  [-0.106553055, 0.06714334, -0.0022430907, -0.0...   \n",
       "1  [-0.029298682, 0.021048546, 0.03234201, -0.003...   \n",
       "2  [0.0020916015, -0.009661912, 0.050255135, -0.0...   \n",
       "3  [0.020856846, -0.038480032, -0.007763977, 0.01...   \n",
       "4  [-0.02089869, -0.04530562, 0.2433449, 0.021318...   \n",
       "\n",
       "                                                Ei+1  \n",
       "0  [-0.029298682, 0.021048546, 0.03234201, -0.003...  \n",
       "1  [0.0020916015, -0.009661912, 0.050255135, -0.0...  \n",
       "2  [0.020856846, -0.038480032, -0.007763977, 0.01...  \n",
       "3  [-0.02089869, -0.04530562, 0.2433449, 0.021318...  \n",
       "4  [0.027081296, 0.008981515, 0.018652983, 0.0216...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_windows.dropna(inplace=True)\n",
    "train_windows.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b70f7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_windows['Ei-1'] = test_windows['Wi-1'].apply(get_word_vector)\n",
    "test_windows['Ei'] = test_windows['Wi'].apply(get_word_vector)\n",
    "test_windows['Ei+1'] = test_windows['Wi+1'].apply(get_word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3abf195b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wi-1</th>\n",
       "      <th>Wi</th>\n",
       "      <th>Wi+1</th>\n",
       "      <th>Wi_POS_tag</th>\n",
       "      <th>Ei-1</th>\n",
       "      <th>Ei</th>\n",
       "      <th>Ei+1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>Non</td>\n",
       "      <td>sono</td>\n",
       "      <td>ADV</td>\n",
       "      <td>[-0.020176327, 0.009958053, 0.021717465, 0.001...</td>\n",
       "      <td>[0.09180346, -0.04038121, -0.15185666, 0.05367...</td>\n",
       "      <td>[0.05899855, -0.021064904, -0.019296896, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non</td>\n",
       "      <td>sono</td>\n",
       "      <td>consentite</td>\n",
       "      <td>AUX</td>\n",
       "      <td>[0.09180346, -0.04038121, -0.15185666, 0.05367...</td>\n",
       "      <td>[0.05899855, -0.021064904, -0.019296896, -0.00...</td>\n",
       "      <td>[0.021040365, -0.04503792, 0.028410899, 0.0026...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sono</td>\n",
       "      <td>consentite</td>\n",
       "      <td>assegnazioni</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[0.05899855, -0.021064904, -0.019296896, -0.00...</td>\n",
       "      <td>[0.021040365, -0.04503792, 0.028410899, 0.0026...</td>\n",
       "      <td>[-0.013494372, 0.017922068, 0.090925455, 0.020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>consentite</td>\n",
       "      <td>assegnazioni</td>\n",
       "      <td>provvisorie</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[0.021040365, -0.04503792, 0.028410899, 0.0026...</td>\n",
       "      <td>[-0.013494372, 0.017922068, 0.090925455, 0.020...</td>\n",
       "      <td>[-0.013625162, 0.011270281, 0.00071706664, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>assegnazioni</td>\n",
       "      <td>provvisorie</td>\n",
       "      <td>nell'ambito</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[-0.013494372, 0.017922068, 0.090925455, 0.020...</td>\n",
       "      <td>[-0.013625162, 0.011270281, 0.00071706664, 0.0...</td>\n",
       "      <td>[0.014763802, -0.014542863, 0.12653038, 0.0160...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Wi-1            Wi          Wi+1 Wi_POS_tag  \\\n",
       "0           <s>           Non          sono        ADV   \n",
       "1           Non          sono    consentite        AUX   \n",
       "2          sono    consentite  assegnazioni       VERB   \n",
       "3    consentite  assegnazioni   provvisorie       NOUN   \n",
       "4  assegnazioni   provvisorie   nell'ambito        ADJ   \n",
       "\n",
       "                                                Ei-1  \\\n",
       "0  [-0.020176327, 0.009958053, 0.021717465, 0.001...   \n",
       "1  [0.09180346, -0.04038121, -0.15185666, 0.05367...   \n",
       "2  [0.05899855, -0.021064904, -0.019296896, -0.00...   \n",
       "3  [0.021040365, -0.04503792, 0.028410899, 0.0026...   \n",
       "4  [-0.013494372, 0.017922068, 0.090925455, 0.020...   \n",
       "\n",
       "                                                  Ei  \\\n",
       "0  [0.09180346, -0.04038121, -0.15185666, 0.05367...   \n",
       "1  [0.05899855, -0.021064904, -0.019296896, -0.00...   \n",
       "2  [0.021040365, -0.04503792, 0.028410899, 0.0026...   \n",
       "3  [-0.013494372, 0.017922068, 0.090925455, 0.020...   \n",
       "4  [-0.013625162, 0.011270281, 0.00071706664, 0.0...   \n",
       "\n",
       "                                                Ei+1  \n",
       "0  [0.05899855, -0.021064904, -0.019296896, -0.00...  \n",
       "1  [0.021040365, -0.04503792, 0.028410899, 0.0026...  \n",
       "2  [-0.013494372, 0.017922068, 0.090925455, 0.020...  \n",
       "3  [-0.013625162, 0.011270281, 0.00071706664, 0.0...  \n",
       "4  [0.014763802, -0.014542863, 0.12653038, 0.0160...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_windows.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3767705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_windows['Ei-1'] = dev_windows['Wi-1'].apply(get_word_vector)\n",
    "dev_windows['Ei'] = dev_windows['Wi'].apply(get_word_vector)\n",
    "dev_windows['Ei+1'] = dev_windows['Wi+1'].apply(get_word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02c0c55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wi-1</th>\n",
       "      <th>Wi</th>\n",
       "      <th>Wi+1</th>\n",
       "      <th>Wi_POS_tag</th>\n",
       "      <th>Ei-1</th>\n",
       "      <th>Ei</th>\n",
       "      <th>Ei+1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>Ha</td>\n",
       "      <td>l'acqua</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[-0.020176327, 0.009958053, 0.021717465, 0.001...</td>\n",
       "      <td>[-0.23689379, -0.04928287, -0.38051826, -0.116...</td>\n",
       "      <td>[0.012642813, 0.006756895, -0.007458575, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l'acqua</td>\n",
       "      <td>calda</td>\n",
       "      <td>,</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[0.012642813, 0.006756895, -0.007458575, -0.00...</td>\n",
       "      <td>[0.011549513, -0.0205097, 0.0013556182, -0.125...</td>\n",
       "      <td>[-0.062408485, -0.043158136, -0.35351264, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calda</td>\n",
       "      <td>,</td>\n",
       "      <td>più</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[0.011549513, -0.0205097, 0.0013556182, -0.125...</td>\n",
       "      <td>[-0.062408485, -0.043158136, -0.35351264, -0.0...</td>\n",
       "      <td>[-0.01851837, -0.064267755, 0.06784441, 0.0319...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>più</td>\n",
       "      <td>o</td>\n",
       "      <td>ADV</td>\n",
       "      <td>[-0.062408485, -0.043158136, -0.35351264, -0.0...</td>\n",
       "      <td>[-0.01851837, -0.064267755, 0.06784441, 0.0319...</td>\n",
       "      <td>[-0.017014293, 0.03295437, -0.21177194, 0.0520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>più</td>\n",
       "      <td>o</td>\n",
       "      <td>meno</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>[-0.01851837, -0.064267755, 0.06784441, 0.0319...</td>\n",
       "      <td>[-0.017014293, 0.03295437, -0.21177194, 0.0520...</td>\n",
       "      <td>[0.0113183465, -0.008037368, 0.060535397, 0.02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Wi-1     Wi     Wi+1 Wi_POS_tag  \\\n",
       "0      <s>     Ha  l'acqua       VERB   \n",
       "1  l'acqua  calda        ,        ADJ   \n",
       "2    calda      ,      più      PUNCT   \n",
       "3        ,    più        o        ADV   \n",
       "4      più      o     meno      CCONJ   \n",
       "\n",
       "                                                Ei-1  \\\n",
       "0  [-0.020176327, 0.009958053, 0.021717465, 0.001...   \n",
       "1  [0.012642813, 0.006756895, -0.007458575, -0.00...   \n",
       "2  [0.011549513, -0.0205097, 0.0013556182, -0.125...   \n",
       "3  [-0.062408485, -0.043158136, -0.35351264, -0.0...   \n",
       "4  [-0.01851837, -0.064267755, 0.06784441, 0.0319...   \n",
       "\n",
       "                                                  Ei  \\\n",
       "0  [-0.23689379, -0.04928287, -0.38051826, -0.116...   \n",
       "1  [0.011549513, -0.0205097, 0.0013556182, -0.125...   \n",
       "2  [-0.062408485, -0.043158136, -0.35351264, -0.0...   \n",
       "3  [-0.01851837, -0.064267755, 0.06784441, 0.0319...   \n",
       "4  [-0.017014293, 0.03295437, -0.21177194, 0.0520...   \n",
       "\n",
       "                                                Ei+1  \n",
       "0  [0.012642813, 0.006756895, -0.007458575, -0.00...  \n",
       "1  [-0.062408485, -0.043158136, -0.35351264, -0.0...  \n",
       "2  [-0.01851837, -0.064267755, 0.06784441, 0.0319...  \n",
       "3  [-0.017014293, 0.03295437, -0.21177194, 0.0520...  \n",
       "4  [0.0113183465, -0.008037368, 0.060535397, 0.02...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_windows.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f1664ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_vectors(row):\n",
    "    return np.concatenate([row['Ei-1'], row['Ei'], row['Ei+1']])\n",
    "\n",
    "train_windows['Concatenated_Embeddings'] = train_windows.apply(concatenate_vectors, axis=1)\n",
    "test_windows['Concatenated_Embeddings'] = test_windows.apply(concatenate_vectors, axis=1)\n",
    "dev_windows['Concatenated_Embeddings'] = dev_windows.apply(concatenate_vectors, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f6c7dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wi-1</th>\n",
       "      <th>Wi</th>\n",
       "      <th>Wi+1</th>\n",
       "      <th>Wi_POS_tag</th>\n",
       "      <th>Ei-1</th>\n",
       "      <th>Ei</th>\n",
       "      <th>Ei+1</th>\n",
       "      <th>Concatenated_Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>Le</td>\n",
       "      <td>infrastrutture</td>\n",
       "      <td>DET</td>\n",
       "      <td>[-0.020176327, 0.009958053, 0.021717465, 0.001...</td>\n",
       "      <td>[-0.106553055, 0.06714334, -0.0022430907, -0.0...</td>\n",
       "      <td>[-0.029298682, 0.021048546, 0.03234201, -0.003...</td>\n",
       "      <td>[-0.020176327, 0.009958053, 0.021717465, 0.001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le</td>\n",
       "      <td>infrastrutture</td>\n",
       "      <td>come</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[-0.106553055, 0.06714334, -0.0022430907, -0.0...</td>\n",
       "      <td>[-0.029298682, 0.021048546, 0.03234201, -0.003...</td>\n",
       "      <td>[0.0020916015, -0.009661912, 0.050255135, -0.0...</td>\n",
       "      <td>[-0.106553055, 0.06714334, -0.0022430907, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>infrastrutture</td>\n",
       "      <td>come</td>\n",
       "      <td>fattore</td>\n",
       "      <td>ADP</td>\n",
       "      <td>[-0.029298682, 0.021048546, 0.03234201, -0.003...</td>\n",
       "      <td>[0.0020916015, -0.009661912, 0.050255135, -0.0...</td>\n",
       "      <td>[0.020856846, -0.038480032, -0.007763977, 0.01...</td>\n",
       "      <td>[-0.029298682, 0.021048546, 0.03234201, -0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>come</td>\n",
       "      <td>fattore</td>\n",
       "      <td>di</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[0.0020916015, -0.009661912, 0.050255135, -0.0...</td>\n",
       "      <td>[0.020856846, -0.038480032, -0.007763977, 0.01...</td>\n",
       "      <td>[-0.02089869, -0.04530562, 0.2433449, 0.021318...</td>\n",
       "      <td>[0.0020916015, -0.009661912, 0.050255135, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fattore</td>\n",
       "      <td>di</td>\n",
       "      <td>competitività</td>\n",
       "      <td>ADP</td>\n",
       "      <td>[0.020856846, -0.038480032, -0.007763977, 0.01...</td>\n",
       "      <td>[-0.02089869, -0.04530562, 0.2433449, 0.021318...</td>\n",
       "      <td>[0.027081296, 0.008981515, 0.018652983, 0.0216...</td>\n",
       "      <td>[0.020856846, -0.038480032, -0.007763977, 0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Wi-1              Wi            Wi+1 Wi_POS_tag  \\\n",
       "0             <s>              Le  infrastrutture        DET   \n",
       "1              Le  infrastrutture            come       NOUN   \n",
       "2  infrastrutture            come         fattore        ADP   \n",
       "3            come         fattore              di       NOUN   \n",
       "4         fattore              di   competitività        ADP   \n",
       "\n",
       "                                                Ei-1  \\\n",
       "0  [-0.020176327, 0.009958053, 0.021717465, 0.001...   \n",
       "1  [-0.106553055, 0.06714334, -0.0022430907, -0.0...   \n",
       "2  [-0.029298682, 0.021048546, 0.03234201, -0.003...   \n",
       "3  [0.0020916015, -0.009661912, 0.050255135, -0.0...   \n",
       "4  [0.020856846, -0.038480032, -0.007763977, 0.01...   \n",
       "\n",
       "                                                  Ei  \\\n",
       "0  [-0.106553055, 0.06714334, -0.0022430907, -0.0...   \n",
       "1  [-0.029298682, 0.021048546, 0.03234201, -0.003...   \n",
       "2  [0.0020916015, -0.009661912, 0.050255135, -0.0...   \n",
       "3  [0.020856846, -0.038480032, -0.007763977, 0.01...   \n",
       "4  [-0.02089869, -0.04530562, 0.2433449, 0.021318...   \n",
       "\n",
       "                                                Ei+1  \\\n",
       "0  [-0.029298682, 0.021048546, 0.03234201, -0.003...   \n",
       "1  [0.0020916015, -0.009661912, 0.050255135, -0.0...   \n",
       "2  [0.020856846, -0.038480032, -0.007763977, 0.01...   \n",
       "3  [-0.02089869, -0.04530562, 0.2433449, 0.021318...   \n",
       "4  [0.027081296, 0.008981515, 0.018652983, 0.0216...   \n",
       "\n",
       "                             Concatenated_Embeddings  \n",
       "0  [-0.020176327, 0.009958053, 0.021717465, 0.001...  \n",
       "1  [-0.106553055, 0.06714334, -0.0022430907, -0.0...  \n",
       "2  [-0.029298682, 0.021048546, 0.03234201, -0.003...  \n",
       "3  [0.0020916015, -0.009661912, 0.050255135, -0.0...  \n",
       "4  [0.020856846, -0.038480032, -0.007763977, 0.01...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_windows.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a72f257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wi-1</th>\n",
       "      <th>Wi</th>\n",
       "      <th>Wi+1</th>\n",
       "      <th>Wi_POS_tag</th>\n",
       "      <th>Ei-1</th>\n",
       "      <th>Ei</th>\n",
       "      <th>Ei+1</th>\n",
       "      <th>Concatenated_Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>Non</td>\n",
       "      <td>sono</td>\n",
       "      <td>ADV</td>\n",
       "      <td>[-0.020176327, 0.009958053, 0.021717465, 0.001...</td>\n",
       "      <td>[0.09180346, -0.04038121, -0.15185666, 0.05367...</td>\n",
       "      <td>[0.05899855, -0.021064904, -0.019296896, -0.00...</td>\n",
       "      <td>[-0.020176327, 0.009958053, 0.021717465, 0.001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non</td>\n",
       "      <td>sono</td>\n",
       "      <td>consentite</td>\n",
       "      <td>AUX</td>\n",
       "      <td>[0.09180346, -0.04038121, -0.15185666, 0.05367...</td>\n",
       "      <td>[0.05899855, -0.021064904, -0.019296896, -0.00...</td>\n",
       "      <td>[0.021040365, -0.04503792, 0.028410899, 0.0026...</td>\n",
       "      <td>[0.09180346, -0.04038121, -0.15185666, 0.05367...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sono</td>\n",
       "      <td>consentite</td>\n",
       "      <td>assegnazioni</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[0.05899855, -0.021064904, -0.019296896, -0.00...</td>\n",
       "      <td>[0.021040365, -0.04503792, 0.028410899, 0.0026...</td>\n",
       "      <td>[-0.013494372, 0.017922068, 0.090925455, 0.020...</td>\n",
       "      <td>[0.05899855, -0.021064904, -0.019296896, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>consentite</td>\n",
       "      <td>assegnazioni</td>\n",
       "      <td>provvisorie</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[0.021040365, -0.04503792, 0.028410899, 0.0026...</td>\n",
       "      <td>[-0.013494372, 0.017922068, 0.090925455, 0.020...</td>\n",
       "      <td>[-0.013625162, 0.011270281, 0.00071706664, 0.0...</td>\n",
       "      <td>[0.021040365, -0.04503792, 0.028410899, 0.0026...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>assegnazioni</td>\n",
       "      <td>provvisorie</td>\n",
       "      <td>nell'ambito</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[-0.013494372, 0.017922068, 0.090925455, 0.020...</td>\n",
       "      <td>[-0.013625162, 0.011270281, 0.00071706664, 0.0...</td>\n",
       "      <td>[0.014763802, -0.014542863, 0.12653038, 0.0160...</td>\n",
       "      <td>[-0.013494372, 0.017922068, 0.090925455, 0.020...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Wi-1            Wi          Wi+1 Wi_POS_tag  \\\n",
       "0           <s>           Non          sono        ADV   \n",
       "1           Non          sono    consentite        AUX   \n",
       "2          sono    consentite  assegnazioni       VERB   \n",
       "3    consentite  assegnazioni   provvisorie       NOUN   \n",
       "4  assegnazioni   provvisorie   nell'ambito        ADJ   \n",
       "\n",
       "                                                Ei-1  \\\n",
       "0  [-0.020176327, 0.009958053, 0.021717465, 0.001...   \n",
       "1  [0.09180346, -0.04038121, -0.15185666, 0.05367...   \n",
       "2  [0.05899855, -0.021064904, -0.019296896, -0.00...   \n",
       "3  [0.021040365, -0.04503792, 0.028410899, 0.0026...   \n",
       "4  [-0.013494372, 0.017922068, 0.090925455, 0.020...   \n",
       "\n",
       "                                                  Ei  \\\n",
       "0  [0.09180346, -0.04038121, -0.15185666, 0.05367...   \n",
       "1  [0.05899855, -0.021064904, -0.019296896, -0.00...   \n",
       "2  [0.021040365, -0.04503792, 0.028410899, 0.0026...   \n",
       "3  [-0.013494372, 0.017922068, 0.090925455, 0.020...   \n",
       "4  [-0.013625162, 0.011270281, 0.00071706664, 0.0...   \n",
       "\n",
       "                                                Ei+1  \\\n",
       "0  [0.05899855, -0.021064904, -0.019296896, -0.00...   \n",
       "1  [0.021040365, -0.04503792, 0.028410899, 0.0026...   \n",
       "2  [-0.013494372, 0.017922068, 0.090925455, 0.020...   \n",
       "3  [-0.013625162, 0.011270281, 0.00071706664, 0.0...   \n",
       "4  [0.014763802, -0.014542863, 0.12653038, 0.0160...   \n",
       "\n",
       "                             Concatenated_Embeddings  \n",
       "0  [-0.020176327, 0.009958053, 0.021717465, 0.001...  \n",
       "1  [0.09180346, -0.04038121, -0.15185666, 0.05367...  \n",
       "2  [0.05899855, -0.021064904, -0.019296896, -0.00...  \n",
       "3  [0.021040365, -0.04503792, 0.028410899, 0.0026...  \n",
       "4  [-0.013494372, 0.017922068, 0.090925455, 0.020...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_windows.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e692785a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wi-1</th>\n",
       "      <th>Wi</th>\n",
       "      <th>Wi+1</th>\n",
       "      <th>Wi_POS_tag</th>\n",
       "      <th>Ei-1</th>\n",
       "      <th>Ei</th>\n",
       "      <th>Ei+1</th>\n",
       "      <th>Concatenated_Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>Ha</td>\n",
       "      <td>l'acqua</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[-0.020176327, 0.009958053, 0.021717465, 0.001...</td>\n",
       "      <td>[-0.23689379, -0.04928287, -0.38051826, -0.116...</td>\n",
       "      <td>[0.012642813, 0.006756895, -0.007458575, -0.00...</td>\n",
       "      <td>[-0.020176327, 0.009958053, 0.021717465, 0.001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l'acqua</td>\n",
       "      <td>calda</td>\n",
       "      <td>,</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[0.012642813, 0.006756895, -0.007458575, -0.00...</td>\n",
       "      <td>[0.011549513, -0.0205097, 0.0013556182, -0.125...</td>\n",
       "      <td>[-0.062408485, -0.043158136, -0.35351264, -0.0...</td>\n",
       "      <td>[0.012642813, 0.006756895, -0.007458575, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calda</td>\n",
       "      <td>,</td>\n",
       "      <td>più</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[0.011549513, -0.0205097, 0.0013556182, -0.125...</td>\n",
       "      <td>[-0.062408485, -0.043158136, -0.35351264, -0.0...</td>\n",
       "      <td>[-0.01851837, -0.064267755, 0.06784441, 0.0319...</td>\n",
       "      <td>[0.011549513, -0.0205097, 0.0013556182, -0.125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>più</td>\n",
       "      <td>o</td>\n",
       "      <td>ADV</td>\n",
       "      <td>[-0.062408485, -0.043158136, -0.35351264, -0.0...</td>\n",
       "      <td>[-0.01851837, -0.064267755, 0.06784441, 0.0319...</td>\n",
       "      <td>[-0.017014293, 0.03295437, -0.21177194, 0.0520...</td>\n",
       "      <td>[-0.062408485, -0.043158136, -0.35351264, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>più</td>\n",
       "      <td>o</td>\n",
       "      <td>meno</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>[-0.01851837, -0.064267755, 0.06784441, 0.0319...</td>\n",
       "      <td>[-0.017014293, 0.03295437, -0.21177194, 0.0520...</td>\n",
       "      <td>[0.0113183465, -0.008037368, 0.060535397, 0.02...</td>\n",
       "      <td>[-0.01851837, -0.064267755, 0.06784441, 0.0319...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Wi-1     Wi     Wi+1 Wi_POS_tag  \\\n",
       "0      <s>     Ha  l'acqua       VERB   \n",
       "1  l'acqua  calda        ,        ADJ   \n",
       "2    calda      ,      più      PUNCT   \n",
       "3        ,    più        o        ADV   \n",
       "4      più      o     meno      CCONJ   \n",
       "\n",
       "                                                Ei-1  \\\n",
       "0  [-0.020176327, 0.009958053, 0.021717465, 0.001...   \n",
       "1  [0.012642813, 0.006756895, -0.007458575, -0.00...   \n",
       "2  [0.011549513, -0.0205097, 0.0013556182, -0.125...   \n",
       "3  [-0.062408485, -0.043158136, -0.35351264, -0.0...   \n",
       "4  [-0.01851837, -0.064267755, 0.06784441, 0.0319...   \n",
       "\n",
       "                                                  Ei  \\\n",
       "0  [-0.23689379, -0.04928287, -0.38051826, -0.116...   \n",
       "1  [0.011549513, -0.0205097, 0.0013556182, -0.125...   \n",
       "2  [-0.062408485, -0.043158136, -0.35351264, -0.0...   \n",
       "3  [-0.01851837, -0.064267755, 0.06784441, 0.0319...   \n",
       "4  [-0.017014293, 0.03295437, -0.21177194, 0.0520...   \n",
       "\n",
       "                                                Ei+1  \\\n",
       "0  [0.012642813, 0.006756895, -0.007458575, -0.00...   \n",
       "1  [-0.062408485, -0.043158136, -0.35351264, -0.0...   \n",
       "2  [-0.01851837, -0.064267755, 0.06784441, 0.0319...   \n",
       "3  [-0.017014293, 0.03295437, -0.21177194, 0.0520...   \n",
       "4  [0.0113183465, -0.008037368, 0.060535397, 0.02...   \n",
       "\n",
       "                             Concatenated_Embeddings  \n",
       "0  [-0.020176327, 0.009958053, 0.021717465, 0.001...  \n",
       "1  [0.012642813, 0.006756895, -0.007458575, -0.00...  \n",
       "2  [0.011549513, -0.0205097, 0.0013556182, -0.125...  \n",
       "3  [-0.062408485, -0.043158136, -0.35351264, -0.0...  \n",
       "4  [-0.01851837, -0.064267755, 0.06784441, 0.0319...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_windows.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5248d3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_windows.iloc[0,7].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cdc1cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADJ', 'AUX', 'ADV',\n",
       "       'VERB', 'PRON', 'CCONJ', 'SCONJ', 'NUM', 'X', 'INTJ', 'SYM'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_windows.Wi_POS_tag.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79fd245",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d1c661",
   "metadata": {},
   "source": [
    "We used only our window embeddings as X sets and we used the 1 hot representation of the POS_tag column as a target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5cecf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = array_2d = np.vstack(train_windows['Concatenated_Embeddings'].to_numpy()) , train_windows.iloc[:,3]\n",
    "X_test, y_test = np.vstack(test_windows['Concatenated_Embeddings'].to_numpy()) , test_windows.iloc[:,3]\n",
    "X_dev, y_dev = np.vstack(dev_windows['Concatenated_Embeddings'].to_numpy()) , dev_windows.iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f20575e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02017633,  0.00995805,  0.02171746, ...,  0.0199761 ,\n",
       "         0.01178493, -0.01623484],\n",
       "       [-0.10655306,  0.06714334, -0.00224309, ..., -0.04036023,\n",
       "        -0.04872986,  0.02742388],\n",
       "       [-0.02929868,  0.02104855,  0.03234201, ...,  0.08926019,\n",
       "         0.01149478, -0.09973563],\n",
       "       ...,\n",
       "       [-0.10548234,  0.04964302,  0.09341467, ...,  0.06388377,\n",
       "         0.09312573, -0.07789223],\n",
       "       [-0.0244427 ,  0.06694292, -0.20528252, ...,  0.0257273 ,\n",
       "        -0.06132365, -0.09340242],\n",
       "       [ 0.11726055,  0.04221974,  0.07346718, ..., -0.01100703,\n",
       "        -0.00072033, -0.00130966]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c470ff3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DET',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'PUNCT',\n",
       " 'ADJ',\n",
       " 'AUX',\n",
       " 'ADV',\n",
       " 'VERB',\n",
       " 'PRON',\n",
       " 'CCONJ',\n",
       " 'SCONJ',\n",
       " 'NUM',\n",
       " 'X',\n",
       " 'INTJ',\n",
       " 'SYM']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4564f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_1_hot[0]: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "target_list = list(train_windows.Wi_POS_tag.unique())\n",
    "\n",
    "y_train_1_hot = lb.fit_transform(y_train)\n",
    "y_dev_1_hot = lb.transform(y_dev)\n",
    "y_test_1_hot = lb.transform(y_test)\n",
    "print('y_train_1_hot[0]: {}'.format(y_train_1_hot[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50870a11",
   "metadata": {},
   "source": [
    "## Initial Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08209c98",
   "metadata": {},
   "source": [
    "We used a simple 1 layer (64 neuron) MLP to see how our data approach performs in solving the classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55d82d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vassi\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vassi\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vassi\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\vassi\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vassi\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "5306/5306 [==============================] - 9s 2ms/step - loss: 0.3642 - accuracy: 0.8950 - val_loss: 0.2405 - val_accuracy: 0.9342\n",
      "Epoch 2/10\n",
      "5306/5306 [==============================] - 8s 2ms/step - loss: 0.1988 - accuracy: 0.9420 - val_loss: 0.2242 - val_accuracy: 0.9385\n",
      "Epoch 3/10\n",
      "5306/5306 [==============================] - 8s 1ms/step - loss: 0.1809 - accuracy: 0.9471 - val_loss: 0.2140 - val_accuracy: 0.9382\n",
      "Epoch 4/10\n",
      "5306/5306 [==============================] - 9s 2ms/step - loss: 0.1702 - accuracy: 0.9492 - val_loss: 0.2049 - val_accuracy: 0.9429\n",
      "Epoch 5/10\n",
      "5306/5306 [==============================] - 8s 1ms/step - loss: 0.1631 - accuracy: 0.9514 - val_loss: 0.2061 - val_accuracy: 0.9428\n",
      "Epoch 6/10\n",
      "5306/5306 [==============================] - 8s 2ms/step - loss: 0.1589 - accuracy: 0.9532 - val_loss: 0.1981 - val_accuracy: 0.9463\n",
      "Epoch 7/10\n",
      "5306/5306 [==============================] - 8s 1ms/step - loss: 0.1555 - accuracy: 0.9539 - val_loss: 0.1983 - val_accuracy: 0.9454\n",
      "Epoch 8/10\n",
      "5306/5306 [==============================] - 8s 2ms/step - loss: 0.1500 - accuracy: 0.9554 - val_loss: 0.2082 - val_accuracy: 0.9415\n",
      "Epoch 9/10\n",
      "5306/5306 [==============================] - 8s 2ms/step - loss: 0.1484 - accuracy: 0.9554 - val_loss: 0.2000 - val_accuracy: 0.9447\n",
      "Epoch 10/10\n",
      "5306/5306 [==============================] - 8s 2ms/step - loss: 0.1457 - accuracy: 0.9564 - val_loss: 0.1960 - val_accuracy: 0.9456\n",
      "628/628 [==============================] - 1s 1ms/step - loss: 0.1793 - accuracy: 0.9456\n",
      "Test Loss: 0.1793, Test Accuracy: 0.9456\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim = X_train.shape[1],\n",
    "                  activation='tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(len(list(train_windows.Wi_POS_tag.unique())),  activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_1_hot,\n",
    "          epochs=10, batch_size=32,verbose=1, validation_data=(X_dev, y_dev_1_hot))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test_1_hot)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf8f99e",
   "metadata": {},
   "source": [
    "The test accuracy for this simple approach was 94.56%, which means that we have good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138424f8",
   "metadata": {},
   "source": [
    "## Model Fine Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f66bd0",
   "metadata": {},
   "source": [
    "We will use keras tuner to tune the hyperparameters of our model, such as layers number, neuron number and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f463211",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b8a169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    layer_index = 0\n",
    "    for i in range(hp.Int(name='num_layers',min_value=1,max_value=3)):\n",
    "        if layer_index == 0:\n",
    "            model.add(Dense(hp.Int(name='hidden_units_'+str(i),min_value=128,max_value=512,step=64),\n",
    "                            activation=hp.Choice(name='activation_layer'+str(i),values=['tanh']),\n",
    "                            input_dim=X_train.shape[1]\n",
    "                           ))\n",
    "            model.add(Dropout(hp.Choice(name='dropout_layer_'+str(i),values=[0.1,0.2,0.3,0.4,0.5])))\n",
    "        else:\n",
    "            model.add(Dense(hp.Int(name='hidden_units_'+str(i),min_value=128,max_value=512,step=64),\n",
    "                            activation=hp.Choice(name='activation_layer'+str(i),values=['tanh'])))\n",
    "            model.add(Dropout(hp.Choice(name='dropout_layer_'+str(i),values=[0.1,0.2,0.3,0.4,0.5])))\n",
    "\n",
    "        layer_index += 1\n",
    "\n",
    "    # Add last layer that produces the logits\n",
    "    model.add(Dense(len(list(train_windows.Wi_POS_tag.unique())),  activation='softmax'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4])\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                  metrics=[CategoricalAccuracy()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7117ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "hidden_units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 512, 'step': 64, 'sampling': 'linear'}\n",
      "activation_layer0 (Choice)\n",
      "{'default': 'tanh', 'conditions': [], 'values': ['tanh'], 'ordered': False}\n",
      "dropout_layer_0 (Choice)\n",
      "{'default': 0.1, 'conditions': [], 'values': [0.1, 0.2, 0.3, 0.4, 0.5], 'ordered': True}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.001, 'conditions': [], 'values': [0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "\n",
    "\n",
    "tuner = kt.RandomSearch(build_model,\n",
    "                        objective=kt.Objective('val_categorical_accuracy',\n",
    "                                               direction='max'),\n",
    "                        max_trials=20,\n",
    "                        directory='KT_directory',\n",
    "                        project_name='KT_tuning')\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=10)\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de5f0d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 15m 59s]\n",
      "val_categorical_accuracy: 0.953667402267456\n",
      "\n",
      "Best val_categorical_accuracy So Far: 0.9610862135887146\n",
      "Total elapsed time: 02h 29m 49s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train_1_hot,\n",
    "             validation_data=(X_dev, y_dev_1_hot), epochs=50, batch_size = 128,\n",
    "             callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54472cdd",
   "metadata": {},
   "source": [
    "After tunning we resulted to the parameters seen below (at trial 07 summary), that produced a MLP with a 0.96 categorical accuracy for our classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bba4424",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in KT_directory\\KT_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_categorical_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "hidden_units_0: 256\n",
      "activation_layer0: tanh\n",
      "dropout_layer_0: 0.5\n",
      "learning_rate: 0.001\n",
      "hidden_units_1: 128\n",
      "activation_layer1: tanh\n",
      "dropout_layer_1: 0.1\n",
      "hidden_units_2: 512\n",
      "activation_layer2: tanh\n",
      "dropout_layer_2: 0.3\n",
      "Score: 0.9610862135887146\n",
      "\n",
      "Trial 16 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "hidden_units_0: 512\n",
      "activation_layer0: tanh\n",
      "dropout_layer_0: 0.4\n",
      "learning_rate: 0.001\n",
      "hidden_units_1: 448\n",
      "activation_layer1: tanh\n",
      "dropout_layer_1: 0.5\n",
      "hidden_units_2: 128\n",
      "activation_layer2: tanh\n",
      "dropout_layer_2: 0.1\n",
      "Score: 0.9609929323196411\n",
      "\n",
      "Trial 14 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "hidden_units_0: 448\n",
      "activation_layer0: tanh\n",
      "dropout_layer_0: 0.2\n",
      "learning_rate: 0.001\n",
      "hidden_units_1: 320\n",
      "activation_layer1: tanh\n",
      "dropout_layer_1: 0.2\n",
      "hidden_units_2: 256\n",
      "activation_layer2: tanh\n",
      "dropout_layer_2: 0.5\n",
      "Score: 0.9602463841438293\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "hidden_units_0: 256\n",
      "activation_layer0: tanh\n",
      "dropout_layer_0: 0.2\n",
      "learning_rate: 0.001\n",
      "hidden_units_1: 320\n",
      "activation_layer1: tanh\n",
      "dropout_layer_1: 0.4\n",
      "hidden_units_2: 128\n",
      "activation_layer2: tanh\n",
      "dropout_layer_2: 0.1\n",
      "Score: 0.9601530432701111\n",
      "\n",
      "Trial 15 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "hidden_units_0: 320\n",
      "activation_layer0: tanh\n",
      "dropout_layer_0: 0.2\n",
      "learning_rate: 0.001\n",
      "hidden_units_1: 320\n",
      "activation_layer1: tanh\n",
      "dropout_layer_1: 0.4\n",
      "hidden_units_2: 512\n",
      "activation_layer2: tanh\n",
      "dropout_layer_2: 0.4\n",
      "Score: 0.9594064950942993\n",
      "\n",
      "Trial 13 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "hidden_units_0: 448\n",
      "activation_layer0: tanh\n",
      "dropout_layer_0: 0.4\n",
      "learning_rate: 0.0001\n",
      "hidden_units_1: 448\n",
      "activation_layer1: tanh\n",
      "dropout_layer_1: 0.2\n",
      "hidden_units_2: 384\n",
      "activation_layer2: tanh\n",
      "dropout_layer_2: 0.1\n",
      "Score: 0.9590332508087158\n",
      "\n",
      "Trial 17 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "hidden_units_0: 192\n",
      "activation_layer0: tanh\n",
      "dropout_layer_0: 0.5\n",
      "learning_rate: 0.001\n",
      "hidden_units_1: 128\n",
      "activation_layer1: tanh\n",
      "dropout_layer_1: 0.3\n",
      "hidden_units_2: 448\n",
      "activation_layer2: tanh\n",
      "dropout_layer_2: 0.3\n",
      "Score: 0.9589399099349976\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "hidden_units_0: 448\n",
      "activation_layer0: tanh\n",
      "dropout_layer_0: 0.1\n",
      "learning_rate: 0.001\n",
      "hidden_units_1: 448\n",
      "activation_layer1: tanh\n",
      "dropout_layer_1: 0.1\n",
      "hidden_units_2: 448\n",
      "activation_layer2: tanh\n",
      "dropout_layer_2: 0.4\n",
      "Score: 0.9587998986244202\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "hidden_units_0: 512\n",
      "activation_layer0: tanh\n",
      "dropout_layer_0: 0.1\n",
      "learning_rate: 0.0001\n",
      "hidden_units_1: 128\n",
      "activation_layer1: tanh\n",
      "dropout_layer_1: 0.1\n",
      "hidden_units_2: 448\n",
      "activation_layer2: tanh\n",
      "dropout_layer_2: 0.3\n",
      "Score: 0.9574001431465149\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "hidden_units_0: 512\n",
      "activation_layer0: tanh\n",
      "dropout_layer_0: 0.1\n",
      "learning_rate: 0.001\n",
      "hidden_units_1: 128\n",
      "activation_layer1: tanh\n",
      "dropout_layer_1: 0.4\n",
      "hidden_units_2: 128\n",
      "activation_layer2: tanh\n",
      "dropout_layer_2: 0.2\n",
      "Score: 0.9544139504432678\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fcc5291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vassi\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "\n",
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, valid_data):\n",
    "        super(Metrics, self).__init__()\n",
    "        self.validation_data = valid_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n",
    "        val_targ = self.validation_data[1]\n",
    "\n",
    "        if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n",
    "            val_targ = np.argmax(val_targ, -1)\n",
    "        val_targ = tf.cast(val_targ,dtype=tf.float32)\n",
    "\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average=\"weighted\",\n",
    "                           zero_division=1)\n",
    "        _val_recall = recall_score(val_targ, val_predict, average=\"weighted\",\n",
    "                                   zero_division=1)\n",
    "        _val_precision = precision_score(val_targ, val_predict, average=\"weighted\",\n",
    "                                         zero_division=1)\n",
    "\n",
    "        logs['val_f1'] = _val_f1\n",
    "        logs['val_recall'] = _val_recall\n",
    "        logs['val_precision'] = _val_precision\n",
    "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22fbb6",
   "metadata": {},
   "source": [
    "## Final Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192db383",
   "metadata": {},
   "source": [
    "We trained the model that the tuner gave us, printed training and validation loss curves and normal and macro averaged scores, for each set (training, development and test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f65cffa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 256)               230656    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               66048     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                8208      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 337808 (1.29 MB)\n",
      "Trainable params: 337808 (1.29 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\vassi\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vassi\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.926054 — val_precision: 0.926397 — val_recall: 0.927585\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92758, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 22s 15ms/step - loss: 0.3535 - accuracy: 0.8928 - val_loss: 0.2493 - val_accuracy: 0.9276 - val_f1: 0.9261 - val_recall: 0.9276 - val_precision: 0.9264\n",
      "Epoch 2/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.932296 — val_precision: 0.935009 — val_recall: 0.931784\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.92758 to 0.93178, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 19s 14ms/step - loss: 0.2168 - accuracy: 0.9339 - val_loss: 0.2256 - val_accuracy: 0.9318 - val_f1: 0.9323 - val_recall: 0.9318 - val_precision: 0.9350\n",
      "Epoch 3/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.940530 — val_precision: 0.941047 — val_recall: 0.940743\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.93178 to 0.94074, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 19s 14ms/step - loss: 0.1943 - accuracy: 0.9414 - val_loss: 0.1995 - val_accuracy: 0.9407 - val_f1: 0.9405 - val_recall: 0.9407 - val_precision: 0.9410\n",
      "Epoch 4/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.943236 — val_precision: 0.943365 — val_recall: 0.943262\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.94074 to 0.94326, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 19s 14ms/step - loss: 0.1812 - accuracy: 0.9442 - val_loss: 0.1909 - val_accuracy: 0.9433 - val_f1: 0.9432 - val_recall: 0.9433 - val_precision: 0.9434\n",
      "Epoch 5/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.941637 — val_precision: 0.941835 — val_recall: 0.942376\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.94326\n",
      "1327/1327 [==============================] - 19s 15ms/step - loss: 0.1723 - accuracy: 0.9467 - val_loss: 0.1916 - val_accuracy: 0.9424 - val_f1: 0.9416 - val_recall: 0.9424 - val_precision: 0.9418\n",
      "Epoch 6/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.948579 — val_precision: 0.948691 — val_recall: 0.948955\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.94326 to 0.94895, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 19s 15ms/step - loss: 0.1644 - accuracy: 0.9497 - val_loss: 0.1746 - val_accuracy: 0.9490 - val_f1: 0.9486 - val_recall: 0.9490 - val_precision: 0.9487\n",
      "Epoch 7/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.949004 — val_precision: 0.949750 — val_recall: 0.949141\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.94895 to 0.94914, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 21s 16ms/step - loss: 0.1590 - accuracy: 0.9512 - val_loss: 0.1787 - val_accuracy: 0.9491 - val_f1: 0.9490 - val_recall: 0.9491 - val_precision: 0.9498\n",
      "Epoch 8/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.946761 — val_precision: 0.947965 — val_recall: 0.946575\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.94914\n",
      "1327/1327 [==============================] - 18s 14ms/step - loss: 0.1537 - accuracy: 0.9527 - val_loss: 0.1804 - val_accuracy: 0.9466 - val_f1: 0.9468 - val_recall: 0.9466 - val_precision: 0.9480\n",
      "Epoch 9/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.951620 — val_precision: 0.951833 — val_recall: 0.951614\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.94914 to 0.95161, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 20s 15ms/step - loss: 0.1500 - accuracy: 0.9540 - val_loss: 0.1676 - val_accuracy: 0.9516 - val_f1: 0.9516 - val_recall: 0.9516 - val_precision: 0.9518\n",
      "Epoch 10/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.953480 — val_precision: 0.953555 — val_recall: 0.953434\n",
      "\n",
      "Epoch 10: val_accuracy improved from 0.95161 to 0.95343, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 19s 14ms/step - loss: 0.1465 - accuracy: 0.9552 - val_loss: 0.1652 - val_accuracy: 0.9534 - val_f1: 0.9535 - val_recall: 0.9534 - val_precision: 0.9536\n",
      "Epoch 11/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.952064 — val_precision: 0.952471 — val_recall: 0.952128\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.95343\n",
      "1327/1327 [==============================] - 19s 14ms/step - loss: 0.1434 - accuracy: 0.9562 - val_loss: 0.1678 - val_accuracy: 0.9521 - val_f1: 0.9521 - val_recall: 0.9521 - val_precision: 0.9525\n",
      "Epoch 12/100\n",
      "670/670 [==============================] - 2s 4ms/step\n",
      " — val_f1: 0.949540 — val_precision: 0.950569 — val_recall: 0.949328\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.95343\n",
      "1327/1327 [==============================] - 20s 15ms/step - loss: 0.1402 - accuracy: 0.9572 - val_loss: 0.1685 - val_accuracy: 0.9493 - val_f1: 0.9495 - val_recall: 0.9493 - val_precision: 0.9506\n",
      "Epoch 13/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.954444 — val_precision: 0.954499 — val_recall: 0.954554\n",
      "\n",
      "Epoch 13: val_accuracy improved from 0.95343 to 0.95455, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 19s 14ms/step - loss: 0.1385 - accuracy: 0.9573 - val_loss: 0.1596 - val_accuracy: 0.9546 - val_f1: 0.9544 - val_recall: 0.9546 - val_precision: 0.9545\n",
      "Epoch 14/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.951867 — val_precision: 0.952340 — val_recall: 0.952034\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.95455\n",
      "1327/1327 [==============================] - 19s 14ms/step - loss: 0.1356 - accuracy: 0.9583 - val_loss: 0.1625 - val_accuracy: 0.9520 - val_f1: 0.9519 - val_recall: 0.9520 - val_precision: 0.9523\n",
      "Epoch 15/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.954038 — val_precision: 0.954289 — val_recall: 0.954227\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.95455\n",
      "1327/1327 [==============================] - 19s 14ms/step - loss: 0.1328 - accuracy: 0.9593 - val_loss: 0.1600 - val_accuracy: 0.9542 - val_f1: 0.9540 - val_recall: 0.9542 - val_precision: 0.9543\n",
      "Epoch 16/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.956564 — val_precision: 0.956554 — val_recall: 0.956654\n",
      "\n",
      "Epoch 16: val_accuracy improved from 0.95455 to 0.95665, saving model to checkpoints\\weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1327/1327 [==============================] - 19s 14ms/step - loss: 0.1308 - accuracy: 0.9601 - val_loss: 0.1545 - val_accuracy: 0.9567 - val_f1: 0.9566 - val_recall: 0.9567 - val_precision: 0.9566\n",
      "Epoch 17/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.953415 — val_precision: 0.953807 — val_recall: 0.953434\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.95665\n",
      "1327/1327 [==============================] - 19s 14ms/step - loss: 0.1287 - accuracy: 0.9602 - val_loss: 0.1623 - val_accuracy: 0.9534 - val_f1: 0.9534 - val_recall: 0.9534 - val_precision: 0.9538\n",
      "Epoch 18/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.956431 — val_precision: 0.956705 — val_recall: 0.956374\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.95665\n",
      "1327/1327 [==============================] - 19s 14ms/step - loss: 0.1287 - accuracy: 0.9606 - val_loss: 0.1582 - val_accuracy: 0.9564 - val_f1: 0.9564 - val_recall: 0.9564 - val_precision: 0.9567\n",
      "Epoch 19/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.955381 — val_precision: 0.955906 — val_recall: 0.955161\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.95665\n",
      "1327/1327 [==============================] - 19s 15ms/step - loss: 0.1268 - accuracy: 0.9612 - val_loss: 0.1610 - val_accuracy: 0.9552 - val_f1: 0.9554 - val_recall: 0.9552 - val_precision: 0.9559\n",
      "Epoch 20/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.956916 — val_precision: 0.957216 — val_recall: 0.956840\n",
      "\n",
      "Epoch 20: val_accuracy improved from 0.95665 to 0.95684, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 22s 17ms/step - loss: 0.1230 - accuracy: 0.9618 - val_loss: 0.1494 - val_accuracy: 0.9568 - val_f1: 0.9569 - val_recall: 0.9568 - val_precision: 0.9572\n",
      "Epoch 21/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.956147 — val_precision: 0.956615 — val_recall: 0.956047\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.95684\n",
      "1327/1327 [==============================] - 19s 14ms/step - loss: 0.1231 - accuracy: 0.9620 - val_loss: 0.1553 - val_accuracy: 0.9560 - val_f1: 0.9561 - val_recall: 0.9560 - val_precision: 0.9566\n",
      "Epoch 22/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.956114 — val_precision: 0.956352 — val_recall: 0.956327\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.95684\n",
      "1327/1327 [==============================] - 20s 15ms/step - loss: 0.1213 - accuracy: 0.9625 - val_loss: 0.1570 - val_accuracy: 0.9563 - val_f1: 0.9561 - val_recall: 0.9563 - val_precision: 0.9564\n",
      "Epoch 23/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.957871 — val_precision: 0.958120 — val_recall: 0.957867\n",
      "\n",
      "Epoch 23: val_accuracy improved from 0.95684 to 0.95787, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 18s 14ms/step - loss: 0.1197 - accuracy: 0.9633 - val_loss: 0.1541 - val_accuracy: 0.9579 - val_f1: 0.9579 - val_recall: 0.9579 - val_precision: 0.9581\n",
      "Epoch 24/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.953616 — val_precision: 0.954520 — val_recall: 0.953434\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.95787\n",
      "1327/1327 [==============================] - 21s 16ms/step - loss: 0.1194 - accuracy: 0.9635 - val_loss: 0.1646 - val_accuracy: 0.9534 - val_f1: 0.9536 - val_recall: 0.9534 - val_precision: 0.9545\n",
      "Epoch 25/100\n",
      "670/670 [==============================] - 2s 4ms/step\n",
      " — val_f1: 0.956070 — val_precision: 0.956461 — val_recall: 0.956140\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.95787\n",
      "1327/1327 [==============================] - 18s 14ms/step - loss: 0.1204 - accuracy: 0.9630 - val_loss: 0.1586 - val_accuracy: 0.9561 - val_f1: 0.9561 - val_recall: 0.9561 - val_precision: 0.9565\n",
      "Epoch 26/100\n",
      "670/670 [==============================] - 3s 4ms/step\n",
      " — val_f1: 0.956861 — val_precision: 0.957492 — val_recall: 0.956560\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.95787\n",
      "1327/1327 [==============================] - 21s 16ms/step - loss: 0.1177 - accuracy: 0.9638 - val_loss: 0.1566 - val_accuracy: 0.9566 - val_f1: 0.9569 - val_recall: 0.9566 - val_precision: 0.9575\n",
      "Epoch 27/100\n",
      "670/670 [==============================] - 3s 4ms/step\n",
      " — val_f1: 0.955589 — val_precision: 0.956213 — val_recall: 0.955300\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.95787\n",
      "1327/1327 [==============================] - 21s 16ms/step - loss: 0.1170 - accuracy: 0.9641 - val_loss: 0.1596 - val_accuracy: 0.9553 - val_f1: 0.9556 - val_recall: 0.9553 - val_precision: 0.9562\n",
      "Epoch 28/100\n",
      "670/670 [==============================] - 3s 4ms/step\n",
      " — val_f1: 0.958016 — val_precision: 0.958344 — val_recall: 0.958100\n",
      "\n",
      "Epoch 28: val_accuracy improved from 0.95787 to 0.95810, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 22s 17ms/step - loss: 0.1174 - accuracy: 0.9639 - val_loss: 0.1548 - val_accuracy: 0.9581 - val_f1: 0.9580 - val_recall: 0.9581 - val_precision: 0.9583\n",
      "Epoch 29/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.954981 — val_precision: 0.955448 — val_recall: 0.954974\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.95810\n",
      "1327/1327 [==============================] - 23s 18ms/step - loss: 0.1148 - accuracy: 0.9649 - val_loss: 0.1579 - val_accuracy: 0.9550 - val_f1: 0.9550 - val_recall: 0.9550 - val_precision: 0.9554\n",
      "Epoch 30/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.956530 — val_precision: 0.956935 — val_recall: 0.956514\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 0.95810\n",
      "1327/1327 [==============================] - 19s 14ms/step - loss: 0.1146 - accuracy: 0.9648 - val_loss: 0.1632 - val_accuracy: 0.9565 - val_f1: 0.9565 - val_recall: 0.9565 - val_precision: 0.9569\n",
      "Epoch 31/100\n",
      "670/670 [==============================] - 3s 4ms/step\n",
      " — val_f1: 0.955430 — val_precision: 0.956420 — val_recall: 0.955161\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.95810\n",
      "1327/1327 [==============================] - 21s 16ms/step - loss: 0.1134 - accuracy: 0.9650 - val_loss: 0.1630 - val_accuracy: 0.9552 - val_f1: 0.9554 - val_recall: 0.9552 - val_precision: 0.9564\n",
      "Epoch 32/100\n",
      "670/670 [==============================] - 2s 4ms/step\n",
      " — val_f1: 0.960355 — val_precision: 0.960486 — val_recall: 0.960340\n",
      "\n",
      "Epoch 32: val_accuracy improved from 0.95810 to 0.96034, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 20s 15ms/step - loss: 0.1129 - accuracy: 0.9652 - val_loss: 0.1518 - val_accuracy: 0.9603 - val_f1: 0.9604 - val_recall: 0.9603 - val_precision: 0.9605\n",
      "Epoch 33/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.959030 — val_precision: 0.959182 — val_recall: 0.958940\n",
      "\n",
      "Epoch 33: val_accuracy did not improve from 0.96034\n",
      "1327/1327 [==============================] - 14s 10ms/step - loss: 0.1112 - accuracy: 0.9657 - val_loss: 0.1523 - val_accuracy: 0.9589 - val_f1: 0.9590 - val_recall: 0.9589 - val_precision: 0.9592\n",
      "Epoch 34/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.960821 — val_precision: 0.961042 — val_recall: 0.960993\n",
      "\n",
      "Epoch 34: val_accuracy improved from 0.96034 to 0.96099, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 10s 7ms/step - loss: 0.1106 - accuracy: 0.9657 - val_loss: 0.1540 - val_accuracy: 0.9610 - val_f1: 0.9608 - val_recall: 0.9610 - val_precision: 0.9610\n",
      "Epoch 35/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.958696 — val_precision: 0.959364 — val_recall: 0.958520\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 14s 10ms/step - loss: 0.1107 - accuracy: 0.9662 - val_loss: 0.1602 - val_accuracy: 0.9585 - val_f1: 0.9587 - val_recall: 0.9585 - val_precision: 0.9594\n",
      "Epoch 36/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.959011 — val_precision: 0.959815 — val_recall: 0.958707\n",
      "\n",
      "Epoch 36: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 15s 11ms/step - loss: 0.1093 - accuracy: 0.9663 - val_loss: 0.1578 - val_accuracy: 0.9587 - val_f1: 0.9590 - val_recall: 0.9587 - val_precision: 0.9598\n",
      "Epoch 37/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.957192 — val_precision: 0.957396 — val_recall: 0.957260\n",
      "\n",
      "Epoch 37: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 13s 10ms/step - loss: 0.1096 - accuracy: 0.9660 - val_loss: 0.1587 - val_accuracy: 0.9573 - val_f1: 0.9572 - val_recall: 0.9573 - val_precision: 0.9574\n",
      "Epoch 38/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.956627 — val_precision: 0.957142 — val_recall: 0.956607\n",
      "\n",
      "Epoch 38: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 12s 9ms/step - loss: 0.1085 - accuracy: 0.9665 - val_loss: 0.1617 - val_accuracy: 0.9566 - val_f1: 0.9566 - val_recall: 0.9566 - val_precision: 0.9571\n",
      "Epoch 39/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.957142 — val_precision: 0.957736 — val_recall: 0.957027\n",
      "\n",
      "Epoch 39: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 11s 8ms/step - loss: 0.1087 - accuracy: 0.9666 - val_loss: 0.1622 - val_accuracy: 0.9570 - val_f1: 0.9571 - val_recall: 0.9570 - val_precision: 0.9577\n",
      "Epoch 40/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.957131 — val_precision: 0.957356 — val_recall: 0.957074\n",
      "\n",
      "Epoch 40: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 15s 11ms/step - loss: 0.1066 - accuracy: 0.9671 - val_loss: 0.1544 - val_accuracy: 0.9571 - val_f1: 0.9571 - val_recall: 0.9571 - val_precision: 0.9574\n",
      "Epoch 41/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.958863 — val_precision: 0.959218 — val_recall: 0.958987\n",
      "\n",
      "Epoch 41: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 15s 11ms/step - loss: 0.1065 - accuracy: 0.9675 - val_loss: 0.1553 - val_accuracy: 0.9590 - val_f1: 0.9589 - val_recall: 0.9590 - val_precision: 0.9592\n",
      "Epoch 42/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.959224 — val_precision: 0.959449 — val_recall: 0.959360\n",
      "\n",
      "Epoch 42: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 14s 10ms/step - loss: 0.1061 - accuracy: 0.9673 - val_loss: 0.1579 - val_accuracy: 0.9594 - val_f1: 0.9592 - val_recall: 0.9594 - val_precision: 0.9594\n",
      "Epoch 43/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.958174 — val_precision: 0.958908 — val_recall: 0.958053\n",
      "\n",
      "Epoch 43: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 11s 8ms/step - loss: 0.1055 - accuracy: 0.9679 - val_loss: 0.1572 - val_accuracy: 0.9581 - val_f1: 0.9582 - val_recall: 0.9581 - val_precision: 0.9589\n",
      "Epoch 44/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.957259 — val_precision: 0.957726 — val_recall: 0.957260\n",
      "\n",
      "Epoch 44: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 10s 7ms/step - loss: 0.1057 - accuracy: 0.9672 - val_loss: 0.1627 - val_accuracy: 0.9573 - val_f1: 0.9573 - val_recall: 0.9573 - val_precision: 0.9577\n",
      "Epoch 45/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.958799 — val_precision: 0.959103 — val_recall: 0.958800\n",
      "\n",
      "Epoch 45: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 14s 11ms/step - loss: 0.1039 - accuracy: 0.9679 - val_loss: 0.1620 - val_accuracy: 0.9588 - val_f1: 0.9588 - val_recall: 0.9588 - val_precision: 0.9591\n",
      "Epoch 46/100\n",
      "670/670 [==============================] - 2s 2ms/step\n",
      " — val_f1: 0.957826 — val_precision: 0.958111 — val_recall: 0.957727\n",
      "\n",
      "Epoch 46: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 15s 11ms/step - loss: 0.1048 - accuracy: 0.9677 - val_loss: 0.1579 - val_accuracy: 0.9577 - val_f1: 0.9578 - val_recall: 0.9577 - val_precision: 0.9581\n",
      "Epoch 47/100\n",
      "670/670 [==============================] - 2s 2ms/step\n",
      " — val_f1: 0.959562 — val_precision: 0.959989 — val_recall: 0.959546\n",
      "\n",
      "Epoch 47: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 13s 10ms/step - loss: 0.1046 - accuracy: 0.9677 - val_loss: 0.1541 - val_accuracy: 0.9595 - val_f1: 0.9596 - val_recall: 0.9595 - val_precision: 0.9600\n",
      "Epoch 48/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.957498 — val_precision: 0.958118 — val_recall: 0.957307\n",
      "\n",
      "Epoch 48: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 13s 10ms/step - loss: 0.1038 - accuracy: 0.9680 - val_loss: 0.1633 - val_accuracy: 0.9573 - val_f1: 0.9575 - val_recall: 0.9573 - val_precision: 0.9581\n",
      "Epoch 49/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.958765 — val_precision: 0.959473 — val_recall: 0.958520\n",
      "\n",
      "Epoch 49: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 13s 10ms/step - loss: 0.1040 - accuracy: 0.9682 - val_loss: 0.1540 - val_accuracy: 0.9585 - val_f1: 0.9588 - val_recall: 0.9585 - val_precision: 0.9595\n",
      "Epoch 50/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.956429 — val_precision: 0.957053 — val_recall: 0.956374\n",
      "\n",
      "Epoch 50: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 12s 9ms/step - loss: 0.1012 - accuracy: 0.9682 - val_loss: 0.1641 - val_accuracy: 0.9564 - val_f1: 0.9564 - val_recall: 0.9564 - val_precision: 0.9571\n",
      "Epoch 51/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.957163 — val_precision: 0.957375 — val_recall: 0.957307\n",
      "\n",
      "Epoch 51: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 15s 11ms/step - loss: 0.1028 - accuracy: 0.9681 - val_loss: 0.1590 - val_accuracy: 0.9573 - val_f1: 0.9572 - val_recall: 0.9573 - val_precision: 0.9574\n",
      "Epoch 52/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.959013 — val_precision: 0.959790 — val_recall: 0.958613\n",
      "\n",
      "Epoch 52: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 15s 12ms/step - loss: 0.1021 - accuracy: 0.9686 - val_loss: 0.1648 - val_accuracy: 0.9586 - val_f1: 0.9590 - val_recall: 0.9586 - val_precision: 0.9598\n",
      "Epoch 53/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.956949 — val_precision: 0.957423 — val_recall: 0.957027\n",
      "\n",
      "Epoch 53: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 10s 8ms/step - loss: 0.1017 - accuracy: 0.9685 - val_loss: 0.1622 - val_accuracy: 0.9570 - val_f1: 0.9569 - val_recall: 0.9570 - val_precision: 0.9574\n",
      "Epoch 54/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.959510 — val_precision: 0.959648 — val_recall: 0.959313\n",
      "\n",
      "Epoch 54: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 11s 8ms/step - loss: 0.1007 - accuracy: 0.9684 - val_loss: 0.1553 - val_accuracy: 0.9593 - val_f1: 0.9595 - val_recall: 0.9593 - val_precision: 0.9596\n",
      "Epoch 55/100\n",
      "670/670 [==============================] - 2s 2ms/step\n",
      " — val_f1: 0.958994 — val_precision: 0.959543 — val_recall: 0.958753\n",
      "\n",
      "Epoch 55: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 13s 10ms/step - loss: 0.1005 - accuracy: 0.9689 - val_loss: 0.1576 - val_accuracy: 0.9588 - val_f1: 0.9590 - val_recall: 0.9588 - val_precision: 0.9595\n",
      "Epoch 56/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.960223 — val_precision: 0.960312 — val_recall: 0.960293\n",
      "\n",
      "Epoch 56: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 15s 11ms/step - loss: 0.1006 - accuracy: 0.9687 - val_loss: 0.1523 - val_accuracy: 0.9603 - val_f1: 0.9602 - val_recall: 0.9603 - val_precision: 0.9603\n",
      "Epoch 57/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.959678 — val_precision: 0.959905 — val_recall: 0.959733\n",
      "\n",
      "Epoch 57: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 15s 11ms/step - loss: 0.1000 - accuracy: 0.9690 - val_loss: 0.1569 - val_accuracy: 0.9597 - val_f1: 0.9597 - val_recall: 0.9597 - val_precision: 0.9599\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.957955 — val_precision: 0.958680 — val_recall: 0.957913\n",
      "\n",
      "Epoch 58: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 16s 12ms/step - loss: 0.0999 - accuracy: 0.9692 - val_loss: 0.1633 - val_accuracy: 0.9579 - val_f1: 0.9580 - val_recall: 0.9579 - val_precision: 0.9587\n",
      "Epoch 59/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.958852 — val_precision: 0.959076 — val_recall: 0.958800\n",
      "\n",
      "Epoch 59: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 15s 11ms/step - loss: 0.1001 - accuracy: 0.9688 - val_loss: 0.1565 - val_accuracy: 0.9588 - val_f1: 0.9589 - val_recall: 0.9588 - val_precision: 0.9591\n",
      "Epoch 60/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.959770 — val_precision: 0.959949 — val_recall: 0.959826\n",
      "\n",
      "Epoch 60: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 14s 11ms/step - loss: 0.0988 - accuracy: 0.9697 - val_loss: 0.1573 - val_accuracy: 0.9598 - val_f1: 0.9598 - val_recall: 0.9598 - val_precision: 0.9599\n",
      "Epoch 61/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.959870 — val_precision: 0.960105 — val_recall: 0.959826\n",
      "\n",
      "Epoch 61: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 14s 11ms/step - loss: 0.0997 - accuracy: 0.9696 - val_loss: 0.1529 - val_accuracy: 0.9598 - val_f1: 0.9599 - val_recall: 0.9598 - val_precision: 0.9601\n",
      "Epoch 62/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.958717 — val_precision: 0.959039 — val_recall: 0.958660\n",
      "\n",
      "Epoch 62: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 10s 8ms/step - loss: 0.0980 - accuracy: 0.9695 - val_loss: 0.1591 - val_accuracy: 0.9587 - val_f1: 0.9587 - val_recall: 0.9587 - val_precision: 0.9590\n",
      "Epoch 63/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.956891 — val_precision: 0.958019 — val_recall: 0.956560\n",
      "\n",
      "Epoch 63: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 10s 7ms/step - loss: 0.0979 - accuracy: 0.9697 - val_loss: 0.1651 - val_accuracy: 0.9566 - val_f1: 0.9569 - val_recall: 0.9566 - val_precision: 0.9580\n",
      "Epoch 64/100\n",
      "670/670 [==============================] - 2s 2ms/step\n",
      " — val_f1: 0.960276 — val_precision: 0.960498 — val_recall: 0.960200\n",
      "\n",
      "Epoch 64: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 14s 11ms/step - loss: 0.0986 - accuracy: 0.9692 - val_loss: 0.1527 - val_accuracy: 0.9602 - val_f1: 0.9603 - val_recall: 0.9602 - val_precision: 0.9605\n",
      "Epoch 65/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.958596 — val_precision: 0.959774 — val_recall: 0.958100\n",
      "\n",
      "Epoch 65: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 15s 11ms/step - loss: 0.0983 - accuracy: 0.9697 - val_loss: 0.1605 - val_accuracy: 0.9581 - val_f1: 0.9586 - val_recall: 0.9581 - val_precision: 0.9598\n",
      "Epoch 66/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.960480 — val_precision: 0.960625 — val_recall: 0.960480\n",
      "\n",
      "Epoch 66: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 13s 10ms/step - loss: 0.0976 - accuracy: 0.9699 - val_loss: 0.1545 - val_accuracy: 0.9605 - val_f1: 0.9605 - val_recall: 0.9605 - val_precision: 0.9606\n",
      "Epoch 67/100\n",
      "670/670 [==============================] - 2s 2ms/step\n",
      " — val_f1: 0.960211 — val_precision: 0.960449 — val_recall: 0.960200\n",
      "\n",
      "Epoch 67: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 11s 8ms/step - loss: 0.0961 - accuracy: 0.9701 - val_loss: 0.1530 - val_accuracy: 0.9602 - val_f1: 0.9602 - val_recall: 0.9602 - val_precision: 0.9604\n",
      "Epoch 68/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.959305 — val_precision: 0.959973 — val_recall: 0.959033\n",
      "\n",
      "Epoch 68: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 11s 8ms/step - loss: 0.0969 - accuracy: 0.9696 - val_loss: 0.1553 - val_accuracy: 0.9590 - val_f1: 0.9593 - val_recall: 0.9590 - val_precision: 0.9600\n",
      "Epoch 69/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.958469 — val_precision: 0.959269 — val_recall: 0.958147\n",
      "\n",
      "Epoch 69: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 16s 12ms/step - loss: 0.0968 - accuracy: 0.9698 - val_loss: 0.1597 - val_accuracy: 0.9581 - val_f1: 0.9585 - val_recall: 0.9581 - val_precision: 0.9593\n",
      "Epoch 70/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.960056 — val_precision: 0.960316 — val_recall: 0.960106\n",
      "\n",
      "Epoch 70: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 14s 10ms/step - loss: 0.0961 - accuracy: 0.9702 - val_loss: 0.1534 - val_accuracy: 0.9601 - val_f1: 0.9601 - val_recall: 0.9601 - val_precision: 0.9603\n",
      "Epoch 71/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.959620 — val_precision: 0.959817 — val_recall: 0.959733\n",
      "\n",
      "Epoch 71: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 13s 10ms/step - loss: 0.0960 - accuracy: 0.9703 - val_loss: 0.1546 - val_accuracy: 0.9597 - val_f1: 0.9596 - val_recall: 0.9597 - val_precision: 0.9598\n",
      "Epoch 72/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.959825 — val_precision: 0.960424 — val_recall: 0.959640\n",
      "\n",
      "Epoch 72: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 13s 9ms/step - loss: 0.0964 - accuracy: 0.9702 - val_loss: 0.1547 - val_accuracy: 0.9596 - val_f1: 0.9598 - val_recall: 0.9596 - val_precision: 0.9604\n",
      "Epoch 73/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.958947 — val_precision: 0.959508 — val_recall: 0.958893\n",
      "\n",
      "Epoch 73: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 14s 11ms/step - loss: 0.0950 - accuracy: 0.9702 - val_loss: 0.1558 - val_accuracy: 0.9589 - val_f1: 0.9589 - val_recall: 0.9589 - val_precision: 0.9595\n",
      "Epoch 74/100\n",
      "670/670 [==============================] - 2s 2ms/step\n",
      " — val_f1: 0.960481 — val_precision: 0.960812 — val_recall: 0.960386\n",
      "\n",
      "Epoch 74: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 11s 9ms/step - loss: 0.0941 - accuracy: 0.9707 - val_loss: 0.1533 - val_accuracy: 0.9604 - val_f1: 0.9605 - val_recall: 0.9604 - val_precision: 0.9608\n",
      "Epoch 75/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.959742 — val_precision: 0.960025 — val_recall: 0.959640\n",
      "\n",
      "Epoch 75: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 14s 11ms/step - loss: 0.0939 - accuracy: 0.9705 - val_loss: 0.1598 - val_accuracy: 0.9596 - val_f1: 0.9597 - val_recall: 0.9596 - val_precision: 0.9600\n",
      "Epoch 76/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.959954 — val_precision: 0.960028 — val_recall: 0.959780\n",
      "\n",
      "Epoch 76: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 14s 11ms/step - loss: 0.0960 - accuracy: 0.9702 - val_loss: 0.1544 - val_accuracy: 0.9598 - val_f1: 0.9600 - val_recall: 0.9598 - val_precision: 0.9600\n",
      "Epoch 77/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.959248 — val_precision: 0.959591 — val_recall: 0.959127\n",
      "\n",
      "Epoch 77: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 13s 10ms/step - loss: 0.0944 - accuracy: 0.9711 - val_loss: 0.1583 - val_accuracy: 0.9591 - val_f1: 0.9592 - val_recall: 0.9591 - val_precision: 0.9596\n",
      "Epoch 78/100\n",
      "670/670 [==============================] - 2s 2ms/step\n",
      " — val_f1: 0.958728 — val_precision: 0.958947 — val_recall: 0.958753\n",
      "\n",
      "Epoch 78: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 12s 9ms/step - loss: 0.0949 - accuracy: 0.9704 - val_loss: 0.1592 - val_accuracy: 0.9588 - val_f1: 0.9587 - val_recall: 0.9588 - val_precision: 0.9589\n",
      "Epoch 79/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.959358 — val_precision: 0.959789 — val_recall: 0.959360\n",
      "\n",
      "Epoch 79: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 10s 7ms/step - loss: 0.0952 - accuracy: 0.9708 - val_loss: 0.1601 - val_accuracy: 0.9594 - val_f1: 0.9594 - val_recall: 0.9594 - val_precision: 0.9598\n",
      "Epoch 80/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.959052 — val_precision: 0.959703 — val_recall: 0.958893\n",
      "\n",
      "Epoch 80: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 15s 11ms/step - loss: 0.0940 - accuracy: 0.9706 - val_loss: 0.1591 - val_accuracy: 0.9589 - val_f1: 0.9591 - val_recall: 0.9589 - val_precision: 0.9597\n",
      "Epoch 81/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.957607 — val_precision: 0.957868 — val_recall: 0.957353\n",
      "\n",
      "Epoch 81: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 13s 10ms/step - loss: 0.0940 - accuracy: 0.9708 - val_loss: 0.1621 - val_accuracy: 0.9574 - val_f1: 0.9576 - val_recall: 0.9574 - val_precision: 0.9579\n",
      "Epoch 82/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.959535 — val_precision: 0.959795 — val_recall: 0.959453\n",
      "\n",
      "Epoch 82: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 12s 9ms/step - loss: 0.0927 - accuracy: 0.9715 - val_loss: 0.1540 - val_accuracy: 0.9595 - val_f1: 0.9595 - val_recall: 0.9595 - val_precision: 0.9598\n",
      "Epoch 83/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.960186 — val_precision: 0.960825 — val_recall: 0.960013\n",
      "\n",
      "Epoch 83: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 12s 9ms/step - loss: 0.0931 - accuracy: 0.9713 - val_loss: 0.1581 - val_accuracy: 0.9600 - val_f1: 0.9602 - val_recall: 0.9600 - val_precision: 0.9608\n",
      "Epoch 84/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.959056 — val_precision: 0.959671 — val_recall: 0.958847\n",
      "\n",
      "Epoch 84: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 11s 8ms/step - loss: 0.0941 - accuracy: 0.9708 - val_loss: 0.1611 - val_accuracy: 0.9588 - val_f1: 0.9591 - val_recall: 0.9588 - val_precision: 0.9597\n",
      "Epoch 85/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.959026 — val_precision: 0.959627 — val_recall: 0.958800\n",
      "\n",
      "Epoch 85: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 16s 12ms/step - loss: 0.0940 - accuracy: 0.9712 - val_loss: 0.1599 - val_accuracy: 0.9588 - val_f1: 0.9590 - val_recall: 0.9588 - val_precision: 0.9596\n",
      "Epoch 86/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.960224 — val_precision: 0.960497 — val_recall: 0.960153\n",
      "\n",
      "Epoch 86: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 14s 10ms/step - loss: 0.0922 - accuracy: 0.9713 - val_loss: 0.1560 - val_accuracy: 0.9602 - val_f1: 0.9602 - val_recall: 0.9602 - val_precision: 0.9605\n",
      "Epoch 87/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.959883 — val_precision: 0.960001 — val_recall: 0.959733\n",
      "\n",
      "Epoch 87: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 14s 10ms/step - loss: 0.0916 - accuracy: 0.9713 - val_loss: 0.1567 - val_accuracy: 0.9597 - val_f1: 0.9599 - val_recall: 0.9597 - val_precision: 0.9600\n",
      "Epoch 88/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.960299 — val_precision: 0.961392 — val_recall: 0.959920\n",
      "\n",
      "Epoch 88: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 13s 10ms/step - loss: 0.0915 - accuracy: 0.9718 - val_loss: 0.1602 - val_accuracy: 0.9599 - val_f1: 0.9603 - val_recall: 0.9599 - val_precision: 0.9614\n",
      "Epoch 89/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.960556 — val_precision: 0.961070 — val_recall: 0.960433\n",
      "\n",
      "Epoch 89: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 10s 7ms/step - loss: 0.0915 - accuracy: 0.9717 - val_loss: 0.1551 - val_accuracy: 0.9604 - val_f1: 0.9606 - val_recall: 0.9604 - val_precision: 0.9611\n",
      "Epoch 90/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.959931 — val_precision: 0.960138 — val_recall: 0.959920\n",
      "\n",
      "Epoch 90: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 11s 8ms/step - loss: 0.0926 - accuracy: 0.9713 - val_loss: 0.1519 - val_accuracy: 0.9599 - val_f1: 0.9599 - val_recall: 0.9599 - val_precision: 0.9601\n",
      "Epoch 91/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.959488 — val_precision: 0.959808 — val_recall: 0.959406\n",
      "\n",
      "Epoch 91: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 11s 8ms/step - loss: 0.0917 - accuracy: 0.9718 - val_loss: 0.1589 - val_accuracy: 0.9594 - val_f1: 0.9595 - val_recall: 0.9594 - val_precision: 0.9598\n",
      "Epoch 92/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.960947 — val_precision: 0.961510 — val_recall: 0.960713\n",
      "\n",
      "Epoch 92: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 14s 11ms/step - loss: 0.0916 - accuracy: 0.9710 - val_loss: 0.1592 - val_accuracy: 0.9607 - val_f1: 0.9609 - val_recall: 0.9607 - val_precision: 0.9615\n",
      "Epoch 93/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.960912 — val_precision: 0.961257 — val_recall: 0.960760\n",
      "\n",
      "Epoch 93: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 10s 8ms/step - loss: 0.0920 - accuracy: 0.9714 - val_loss: 0.1512 - val_accuracy: 0.9608 - val_f1: 0.9609 - val_recall: 0.9608 - val_precision: 0.9613\n",
      "Epoch 94/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.959402 — val_precision: 0.960415 — val_recall: 0.958987\n",
      "\n",
      "Epoch 94: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 14s 10ms/step - loss: 0.0915 - accuracy: 0.9716 - val_loss: 0.1591 - val_accuracy: 0.9590 - val_f1: 0.9594 - val_recall: 0.9590 - val_precision: 0.9604\n",
      "Epoch 95/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.960232 — val_precision: 0.960999 — val_recall: 0.960060\n",
      "\n",
      "Epoch 95: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 13s 10ms/step - loss: 0.0899 - accuracy: 0.9723 - val_loss: 0.1592 - val_accuracy: 0.9601 - val_f1: 0.9602 - val_recall: 0.9601 - val_precision: 0.9610\n",
      "Epoch 96/100\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      " — val_f1: 0.958855 — val_precision: 0.959990 — val_recall: 0.958427\n",
      "\n",
      "Epoch 96: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 11s 9ms/step - loss: 0.0896 - accuracy: 0.9719 - val_loss: 0.1647 - val_accuracy: 0.9584 - val_f1: 0.9589 - val_recall: 0.9584 - val_precision: 0.9600\n",
      "Epoch 97/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.960035 — val_precision: 0.960998 — val_recall: 0.959733\n",
      "\n",
      "Epoch 97: val_accuracy did not improve from 0.96099\n",
      "1327/1327 [==============================] - 10s 8ms/step - loss: 0.0898 - accuracy: 0.9721 - val_loss: 0.1628 - val_accuracy: 0.9597 - val_f1: 0.9600 - val_recall: 0.9597 - val_precision: 0.9610\n",
      "Epoch 98/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.961726 — val_precision: 0.962062 — val_recall: 0.961553\n",
      "\n",
      "Epoch 98: val_accuracy improved from 0.96099 to 0.96155, saving model to checkpoints\\weights.hdf5\n",
      "1327/1327 [==============================] - 13s 10ms/step - loss: 0.0916 - accuracy: 0.9717 - val_loss: 0.1549 - val_accuracy: 0.9616 - val_f1: 0.9617 - val_recall: 0.9616 - val_precision: 0.9621\n",
      "Epoch 99/100\n",
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.961480 — val_precision: 0.961487 — val_recall: 0.961320\n",
      "\n",
      "Epoch 99: val_accuracy did not improve from 0.96155\n",
      "1327/1327 [==============================] - 13s 10ms/step - loss: 0.0901 - accuracy: 0.9719 - val_loss: 0.1558 - val_accuracy: 0.9613 - val_f1: 0.9615 - val_recall: 0.9613 - val_precision: 0.9615\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670/670 [==============================] - 1s 2ms/step\n",
      " — val_f1: 0.961081 — val_precision: 0.961856 — val_recall: 0.960760\n",
      "\n",
      "Epoch 100: val_accuracy did not improve from 0.96155\n",
      "1327/1327 [==============================] - 12s 9ms/step - loss: 0.0901 - accuracy: 0.9719 - val_loss: 0.1570 - val_accuracy: 0.9608 - val_f1: 0.9611 - val_recall: 0.9608 - val_precision: 0.9619\n",
      "\n",
      "Training time: 00:25:13 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim = X_train.shape[1],\n",
    "                  activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(len(list(train_windows.Wi_POS_tag.unique())),  activation='softmax'))\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "#Configures the model for training.\n",
    "#CategoricalCrossentropy: Computes the crossentropy loss between the labels and predictions.\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"]\n",
    "    )\n",
    "if not os.path.exists('./checkpoints'):\n",
    "  os.makedirs('./checkpoints')\n",
    "# Callback to save the Keras model or model weights at some frequency.\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'checkpoints/weights.hdf5',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=2,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    "    )\n",
    "start_training_time = time.time()\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_1_hot,\n",
    "    validation_data=(X_dev, y_dev_1_hot),\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    callbacks=[Metrics(valid_data=(X_dev, y_dev_1_hot)), checkpoint]\n",
    "    )\n",
    "end_training_time = time.time()\n",
    "\n",
    "print(f'\\nTraining time: {time.strftime(\"%H:%M:%S\", time.gmtime(end_training_time - start_training_time))} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af4c5cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c171f28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADJ', 'AUX', 'ADV',\n",
       "       'VERB', 'PRON', 'CCONJ', 'SCONJ', 'NUM', 'X', 'INTJ'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reset_index(drop=True,inplace=True)\n",
    "dict_match = {}\n",
    "for i in range(169777):\n",
    "    dict_match[y_train[i]] = y_train_1_hot[i]\n",
    "    \n",
    "modified_dict = {key: np.argmax(value,-1) for key, value in dict_match.items()}\n",
    "y_dev_num = y_dev.replace(modified_dict) \n",
    "y_dev_num.reset_index(drop=True,inplace=True)\n",
    "labels = train_windows.Wi_POS_tag.unique()\n",
    "labels = labels[labels != 'SYM']\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76477494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vassi\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim = X_train.shape[1],\n",
    "                  activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(len(list(train_windows.Wi_POS_tag.unique())),  activation='softmax'))\n",
    "\n",
    "# Load weights from the pre-trained model\n",
    "model.load_weights(\"checkpoints/weights.hdf5\")\n",
    "# model.compile(\n",
    "#     loss='categorical_crossentropy',\n",
    "#     optimizer=Adam(lr=0.001),\n",
    "#     metrics=[\"accuracy\"]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a25ff29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5306/5306 [==============================] - 19s 3ms/step\n",
      "-----------Predection Scores for Training Set-----------\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DET       0.97      0.96      0.97     14945\n",
      "        NOUN       1.00      1.00      1.00     19944\n",
      "         ADP       0.96      0.98      0.97      8361\n",
      "       PROPN       0.98      0.99      0.98      7259\n",
      "       PUNCT       0.98      0.97      0.98      6640\n",
      "         ADJ       0.99      0.99      0.99     17129\n",
      "         AUX       0.64      0.88      0.74        33\n",
      "         ADV       0.99      0.99      0.99     40002\n",
      "        VERB       0.97      0.98      0.97      3955\n",
      "        PRON       0.94      0.95      0.94      6332\n",
      "       CCONJ       1.00      1.00      1.00      9013\n",
      "       SCONJ       1.00      1.00      1.00     18128\n",
      "         NUM       0.85      0.85      0.85      1795\n",
      "           X       1.00      0.89      0.94         9\n",
      "        INTJ       0.98      0.97      0.97     15993\n",
      "         SYM       0.96      0.99      0.97       239\n",
      "\n",
      "    accuracy                           0.98    169777\n",
      "   macro avg       0.95      0.96      0.95    169777\n",
      "weighted avg       0.98      0.98      0.98    169777\n",
      "\n",
      "AUC Scores for Classes\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      "AUC for class DET: 0.9949192620690681\n",
      "AUC for class NOUN: 0.999866656721077\n",
      "AUC for class ADP: 0.9981552814600447\n",
      "AUC for class PROPN: 0.9998825358537157\n",
      "AUC for class PUNCT: 0.9979990030163888\n",
      "AUC for class ADJ: 0.9992596659738769\n",
      "AUC for class AUX: 0.9999222237777466\n",
      "AUC for class ADV: 0.9964383648019225\n",
      "AUC for class VERB: 0.9941494143983781\n",
      "AUC for class PRON: 0.9987112471184192\n",
      "AUC for class CCONJ: 0.9992963404880446\n",
      "AUC for class SCONJ: 0.9999997978625531\n",
      "AUC for class NUM: 0.9981993345490942\n",
      "AUC for class INTJ: 0.9964526113017038\n",
      "AUC for class SYM: 0.9890513935652825\n",
      "Macro AUC: 0.9351439458098323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "dict_match = {}\n",
    "for i in range(169777):\n",
    "    dict_match[y_train[i]] = y_train_1_hot[i]\n",
    "    \n",
    "modified_dict = {key: np.argmax(value,-1) for key, value in dict_match.items()}\n",
    "labels = train_windows.Wi_POS_tag.unique()\n",
    "\n",
    "def print_metrics(X, y, labels, set_name):\n",
    "    \n",
    "    if set_name != \"Training Set\":\n",
    "        labels = labels[labels != 'SYM']\n",
    "        \n",
    "    y_num = y.replace(modified_dict) \n",
    "    y_num.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    predictions = np.argmax(model.predict(X), -1)\n",
    "    print(f\"-----------Predection Scores for {set_name}-----------\")\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_num, predictions,\n",
    "                                target_names=labels))\n",
    "    print(\"AUC Scores for Classes\")\n",
    "    y_probs = model.predict(X_dev)\n",
    "    n_classes = len(labels)\n",
    "    macro_auc = 0\n",
    "    for i in range(n_classes):\n",
    "        class_indices = (y_dev_num == i)\n",
    "        if any(class_indices):\n",
    "            class_auc = roc_auc_score((y_dev_num == i).astype(int), y_probs[:, i])\n",
    "            print(f\"AUC for class {labels[i]}: {class_auc}\")\n",
    "            macro_auc += class_auc\n",
    "    macro_auc = macro_auc/n_classes\n",
    "    print(f\"Macro AUC: {macro_auc}\")\n",
    "\n",
    "print_metrics(X_train, y_train, labels, \"Training Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2dafd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670/670 [==============================] - 2s 3ms/step\n",
      "-----------Predection Scores for Development Set-----------\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DET       0.91      0.91      0.91      2258\n",
      "        NOUN       0.99      0.99      0.99      3064\n",
      "         ADP       0.93      0.97      0.95       832\n",
      "       PROPN       0.98      0.98      0.98       850\n",
      "       PUNCT       0.95      0.94      0.95       739\n",
      "         ADJ       0.98      0.98      0.98      1864\n",
      "         AUX       0.50      0.33      0.40         3\n",
      "         ADV       0.98      0.96      0.97      5946\n",
      "        VERB       0.95      0.94      0.95       515\n",
      "        PRON       0.91      0.92      0.92       898\n",
      "       CCONJ       0.92      0.97      0.94       334\n",
      "       SCONJ       1.00      1.00      1.00      2041\n",
      "         NUM       0.70      0.80      0.75       173\n",
      "           X       0.93      0.94      0.93      1867\n",
      "        INTJ       0.67      0.73      0.70        48\n",
      "\n",
      "    accuracy                           0.96     21432\n",
      "   macro avg       0.89      0.89      0.89     21432\n",
      "weighted avg       0.96      0.96      0.96     21432\n",
      "\n",
      "AUC Scores for Classes\n",
      "670/670 [==============================] - 2s 3ms/step\n",
      "AUC for class DET: 0.9949192620690681\n",
      "AUC for class NOUN: 0.999866656721077\n",
      "AUC for class ADP: 0.9981552814600447\n",
      "AUC for class PROPN: 0.9998825358537157\n",
      "AUC for class PUNCT: 0.9979990030163888\n",
      "AUC for class ADJ: 0.9992596659738769\n",
      "AUC for class AUX: 0.9999222237777466\n",
      "AUC for class ADV: 0.9964383648019225\n",
      "AUC for class VERB: 0.9941494143983781\n",
      "AUC for class PRON: 0.9987112471184192\n",
      "AUC for class CCONJ: 0.9992963404880446\n",
      "AUC for class SCONJ: 0.9999997978625531\n",
      "AUC for class NUM: 0.9981993345490942\n",
      "AUC for class INTJ: 0.9964526113017038\n",
      "Macro AUC: 0.9315501159594689\n"
     ]
    }
   ],
   "source": [
    "print_metrics(X_dev, y_dev, labels, \"Development Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d34ada5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628/628 [==============================] - 2s 3ms/step\n",
      "-----------Predection Scores for Test Set-----------\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DET       0.89      0.89      0.89      1403\n",
      "        NOUN       0.99      0.99      0.99      2248\n",
      "         ADP       0.92      0.96      0.94      1182\n",
      "       PROPN       0.97      0.98      0.97       999\n",
      "       PUNCT       0.98      0.93      0.96       752\n",
      "         ADJ       0.98      0.98      0.98      2097\n",
      "         AUX       0.64      0.88      0.74         8\n",
      "         ADV       0.97      0.97      0.97      4287\n",
      "        VERB       0.92      0.93      0.92       342\n",
      "        PRON       0.90      0.88      0.89      1047\n",
      "       CCONJ       0.98      0.99      0.98      1127\n",
      "       SCONJ       1.00      1.00      1.00      2152\n",
      "         NUM       0.71      0.81      0.76       315\n",
      "           X       0.95      0.94      0.94      2075\n",
      "        INTJ       0.54      0.56      0.55        34\n",
      "\n",
      "    accuracy                           0.96     20068\n",
      "   macro avg       0.89      0.91      0.90     20068\n",
      "weighted avg       0.96      0.96      0.96     20068\n",
      "\n",
      "AUC Scores for Classes\n",
      "670/670 [==============================] - 2s 4ms/step\n",
      "AUC for class DET: 0.9949192620690681\n",
      "AUC for class NOUN: 0.999866656721077\n",
      "AUC for class ADP: 0.9981552814600447\n",
      "AUC for class PROPN: 0.9998825358537157\n",
      "AUC for class PUNCT: 0.9979990030163888\n",
      "AUC for class ADJ: 0.9992596659738769\n",
      "AUC for class AUX: 0.9999222237777466\n",
      "AUC for class ADV: 0.9964383648019225\n",
      "AUC for class VERB: 0.9941494143983781\n",
      "AUC for class PRON: 0.9987112471184192\n",
      "AUC for class CCONJ: 0.9992963404880446\n",
      "AUC for class SCONJ: 0.9999997978625531\n",
      "AUC for class NUM: 0.9981993345490942\n",
      "AUC for class INTJ: 0.9964526113017038\n",
      "Macro AUC: 0.9315501159594689\n"
     ]
    }
   ],
   "source": [
    "print_metrics(X_test, y_test, labels, \"Test Set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
